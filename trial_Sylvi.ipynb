{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mapper(key, value):\n",
    "    # key: None\n",
    "    # value: one line of input file\n",
    "    if False:\n",
    "        yield \"key\", \"value\"  # this is how you yield a key, value pair\n",
    "\n",
    "\n",
    "def reducer(key, values):\n",
    "    # key: key from mapper used to aggregate\n",
    "    # values: list of all value for that key\n",
    "    if False:\n",
    "        yield \"key\", \"value\"  # this is how you yield a key, value pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import argparse\n",
    "import glob\n",
    "import imp\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "import resource\n",
    "import sys\n",
    "from sets import Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:64: DeprecationWarning: the sets module is deprecated\n",
      "usage: __main__.py [-h] [--log] source_file\n",
      "__main__.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain, islice\n",
    "try:\n",
    "    import simplejson as json\n",
    "except:\n",
    "    import json\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "\n",
    "def chunks(iterable, size=10):\n",
    "    iterator = iter(iterable)\n",
    "    for first in iterator:\n",
    "        yield list(chain([first], islice(iterator, size - 1)))\n",
    "\n",
    "\n",
    "def isolated_batch_call(f, arguments):\n",
    "    \"\"\"Calls the function f in a separate process and returns list of results\"\"\"\n",
    "\n",
    "    def lf(q):\n",
    "        r = []\n",
    "        for args in arguments:\n",
    "            r.extend(list(f(*args)))\n",
    "        q.put(r)\n",
    "\n",
    "    q = multiprocessing.Queue()\n",
    "    p = multiprocessing.Process(target=lf, args=(q, ))\n",
    "    p.start()\n",
    "    # Set timeout for individual mappers and reducers.\n",
    "    p.join()\n",
    "    return q.get()\n",
    "\n",
    "\n",
    "def mapreduce(input, mapper, reducer, batch_size=50, log=False):\n",
    "    \"\"\"Python function that runs a worst-case map reduce framework on the provided data\n",
    "\n",
    "    Args:\n",
    "      input -- list or generator of (key, value) tuple\n",
    "      mapper -- function that takes (key, value) pair as input and returns iterable key-value pairs\n",
    "      reducer -- function that takes key + list of values and outputs (key, value) pair\n",
    "      log -- whether log messages should be generated (default: False)\n",
    "\n",
    "    Returns list of (key, value pairs)\n",
    "    \"\"\"\n",
    "    # Set initial random seed\n",
    "    random.seed(0)\n",
    "    # Run mappers\n",
    "    if log: logger.info(\"Starting mapping phase!\")\n",
    "    d = defaultdict(list)\n",
    "    for pairs_generator in chunks(input, batch_size):\n",
    "        pairs = list(pairs_generator)\n",
    "        if log:\n",
    "            for k, v in pairs:\n",
    "                logger.debug(\"  Running mapper for '%s' key with value '%s'...\", k, v)\n",
    "        for k2, v2 in isolated_batch_call(mapper, pairs):\n",
    "            if log: logger.debug(\"    Mapper produced (%s, %s) pair...\", k2, v2)\n",
    "            if not isinstance(k2, (basestring, int, float)):\n",
    "                raise Exception(\"Keys must be strings, ints or floats (provided '%s')!\"% k2)\n",
    "            d[k2].append(v2)\n",
    "    if log: logger.info(\"Finished mapping phase!\")\n",
    "    # Random permutations of both keys and values.\n",
    "    keys = d.keys()\n",
    "    random.shuffle(keys)\n",
    "    for k in keys:\n",
    "        random.shuffle(d[k])\n",
    "    # Run reducers\n",
    "    if log: logger.info(\"Starting reducing phase!\")\n",
    "    res = []\n",
    "    for key_chunk in chunks(keys, batch_size):\n",
    "        if log:\n",
    "            for k in key_chunk:\n",
    "                logger.debug(\"  Running reducer for '%s' key with values '%s'...\", k, d[k])\n",
    "        r = isolated_batch_call(reducer, ([k, d[k]] for k in key_chunk))\n",
    "        for k, v in r:\n",
    "            if log: logger.debug(\"    Reducer produced (%s, %s) pair...\", k, v)\n",
    "        res.extend(r)\n",
    "    if log: logger.info(\"Finished reducing phase!\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def yield_pattern(path):\n",
    "    \"\"\"Yield lines from each file in specified folder\"\"\"\n",
    "    for i in glob.iglob(path):\n",
    "        if os.path.isfile(i):\n",
    "            with open(i, \"r\") as fin:\n",
    "                for line in fin:\n",
    "                    yield None, line\n",
    "\n",
    "\n",
    "def import_from_file(f):\n",
    "    \"\"\"Import code from the specified file\"\"\"\n",
    "    mod = imp.new_module(\"mod\")\n",
    "    exec f in mod.__dict__\n",
    "    return mod\n",
    "\n",
    "\n",
    "def evaluate(reported_duplicates, true_duplicates):\n",
    "    tp = fp = fn = 0\n",
    "    seen = Set()\n",
    "    # Count true positives and false positives.\n",
    "    for pair in reported_duplicates:\n",
    "        # Skip already seen pairs.\n",
    "        if pair in seen: continue\n",
    "        seen.add(pair)\n",
    "        if pair in true_duplicates:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    # Count false negatives.\n",
    "    for pair in true_duplicates:\n",
    "        if pair not in reported_duplicates:\n",
    "            fn += 1\n",
    "\n",
    "    logging.info(\"TP=%d, FP=%d, FN=%d\", tp, fp, fn)\n",
    "    \n",
    "    # If either precision or recall are zero, return zero.\n",
    "    if (tp + fp == 0) or (tp + fn == 0):\n",
    "        return 0\n",
    "    \n",
    "    precision = 1.0 * tp / (tp + fp)\n",
    "    recall = 1.0 * tp / (tp + fn)\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "\n",
    "    f1 = 2.0 * precision * recall / (precision + recall)\n",
    "    logging.info(\"Precision: %.3f, recall: %.3f, F1 score: %.3f\",\n",
    "                 precision, recall, f1)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def run(sourcestring, input_pattern, duplicates_file, batch, log):\n",
    "    mod = import_from_file(sourcestring)\n",
    "    input = yield_pattern(input_pattern)\n",
    "\n",
    "    reported_duplicates = Set()\n",
    "    for output in mapreduce(input, mod.mapper, mod.reducer, batch, log):\n",
    "        reported_duplicates.add(output)\n",
    "\n",
    "    true_duplicates = Set()\n",
    "    with open(duplicates_file, \"r\") as inf:\n",
    "        for line in inf:\n",
    "            a, b = line.strip().split(\",\")\n",
    "            true_duplicates.add((int(a), int(b)))\n",
    "\n",
    "    return evaluate(reported_duplicates, true_duplicates)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=__doc__,\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter)\n",
    "    parser.add_argument(\n",
    "        'source_file', help='.py file with mapper and reducer function')\n",
    "    parser.add_argument(\n",
    "        '--log', '-l', help='Enable logging for debugging', action='store_true')\n",
    "    args = parser.parse_args()\n",
    "    INPUT_PATTERN = \"data/handout_shingles.txt\"\n",
    "    DUPLICATES = \"data/handout_duplicates.txt\"\n",
    "    BATCH = 50\n",
    "    \n",
    "    with open(args.source_file, \"r\") as fin:\n",
    "        source = fin.read()\n",
    "\n",
    "    print run(source, INPUT_PATTERN, DUPLICATES, BATCH, args.log)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
